{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d48e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682710e4",
   "metadata": {},
   "source": [
    "CNN(Convloutional Neural Network) - 합성곱 신경망  \n",
    "\n",
    "데이터 획득  \n",
    "MNIST 데이터를 내려받아 학습 데이터 및 테스트 데이터로 분리해서 저장한다.  \n",
    "MNIST 데이터는 28*28의 픽셀 데이터로 각 픽셀은 흑백 사진과 같이 0부터 255 사이의 그레이스케일을 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23780235",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3fc3c2",
   "metadata": {},
   "source": [
    "학습 데이터에서 검증 데이터 분리하기  \n",
    "학습 중간마다 검증 데이터로 모델의 성능을 측정하면 모델 학습이 제대로 진행되는지 검증 정확도를 확인할 수 있고 학습 정확도는 증가하는데 검증 정확도가 증가하지  \n",
    "않거나 떨어질 때 조기 종료를 구현할 수 있다 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ada435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6만 개의 학습 데이터 중에서 1만개의 학습 데이터를 검증 데이터로 따로 저장한다. \n",
    "x_val = x_train[50000:] # 학습 데이터 6만개 중에서 학습 결과 검증에 사용할 데이터 1만개\n",
    "x_train = x_train[:50000] # 학습 데이터 6만개 중에서 학습에 사용할 데이터 5만개\n",
    "y_val = y_train[50000:] # 검증 데이터 실제값\n",
    "y_train = y_train[:50000] # 학습 데이터 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac706ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터: (50000, 28, 28)\n",
      "검증 데이터: (10000, 28, 28)\n",
      "테스트 데이터: (10000, 28, 28)\n",
      "학습 데이터 레이블 : (50000, 28, 28)\n",
      "검증 데이터 레이블 : (10000,)\n",
      "테스트 데이터 레이블 : (10000,)\n",
      "테스트 데이터 레이블: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('학습 데이터: {}'.format(x_train.shape)) # 학습 데이터는 5만개 이고 28 * 28 픽셀의 이미지 이다 \n",
    "print('검증 데이터: {}'.format(x_val.shape)) # 검증 데이터는 1만개 이고 28 * 28 픽셀의 이미지 이다 \n",
    "print('테스트 데이터: {}'.format(x_val.shape)) # 테스트 데이터는 1만개 이고 28* 28 픽셀의 이미지 이다 \n",
    "print('학습 데이터 레이블 : {}'.format(x_train.shape)) \n",
    "print('검증 데이터 레이블 : {}'.format(y_val.shape)) \n",
    "print('테스트 데이터 레이블 : {}'.format(y_test.shape))\n",
    "print('테스트 데이터 레이블: {}'.format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecb23bd",
   "metadata": {},
   "source": [
    "학습 데이터를 출력해보면 데이터가 0부터 255사이의 숫자(그레이스케일)로 구성된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf468fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0 \n",
      "  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])\n",
    "for i in x_train[0]:\n",
    "    for j in i:\n",
    "        print('{:3d} '.format(j), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647d159",
   "metadata": {},
   "source": [
    "컴퓨터 비전에서 많이 사용되는 딥러닝 모델인 CNN의 장점은 다층 퍼셉트론과 비교하면 쉽게 이해할 수 있다.  \n",
    "\n",
    "다층 퍼셉트론의 첫번째 단점은 고유 이미지의 생김새를 사용할 수 없다는 것이다 .  \n",
    "다층 퍼셉트론의 경우 데이터를 입력하기 위해서 2차원 평면에 있는 숫자를 1차원 배열로 변환해야 한다. 1차원 배열로 변환된 데이터는 원래 고유 숫자 이미지를 떠올리기 쉽지 않다.  \n",
    "1차원으로 변환된 데이터를 입력으로 받는 다층 퍼셉트론의 경우, 고유 데이터가 2차원 평면에서 가지고 있던 지역 정보를 잃어버린 채로 학습을 시작한다.  \n",
    "\n",
    "두번째 단점은 다층 퍼센트론은 픽셀 하나 하나의 변화에 상당히 민감하다는 것이다 . \n",
    "이미지의 생김새 정보를 사용할 수 없는 다층 퍼셉트론은 가지고 있는 정보가 픽셀 정보 밖에 없기 때문에 픽셀 한두 개의 차이가 모델 예측에 큰 영향을 끼치게 된다. \n",
    "\n",
    "세번째 단점은 다층 퍼셉트론은 픽셀 한두 개의 정보에도 민감하게 반응하기 위해 상당히 많은 변수를 모델 안에 가지고 있다는 것이다. 이로 인해 모델의 크기를 크게   \n",
    "만들고, 학습 시간이 오래 걸리며, 자칫 잘못하면 과대 적합된 모델이 되기 쉽다. \n",
    "\n",
    "생김새 정보 획득하기  \n",
    "<img src=\"./images/CNN1.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd4f64",
   "metadata": {},
   "source": [
    "두 개의 비슷한 생김새의 숫자 2가 있을 때 생김새가 달라도 머리와 꼬리 부분이 있과 머리와 꼬리를 잇는 대각선이 있다면 단번에 숫자 2임을 판별할 수 있다.  \n",
    "\n",
    "CNN은 어떻게 특징을 찾아내는가 ?\n",
    "\n",
    "<img src=\"./images/CNN2.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a38ec4",
   "metadata": {},
   "source": [
    "위 그림에서 필터 또는 커널이라고 불리는 반 투명한 네모 상자가 이미지 왼쪽 상단에서 조금씩 이동하면서 오른쪽 최하단까지 이동한다.  \n",
    "이처럼 필터를 이동하는 기법을 스트라이드(stride)라고 한다.   \n",
    "필터는 특징을 추출하기 위한 네모 상자이고 이필터와 겹치는 이미지 부분을 수용영역이라 부른다.  \n",
    "\n",
    "아래 그림에서 대각선 필터는 숫자 2로부터 두곳의 대각선 특징을 감지한다. 숫자 1에서는 대각선 특징을 발견하지 못한다.  \n",
    "<img src=\"./images/CNN3.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9318cdd",
   "metadata": {},
   "source": [
    "모든 딥러닝 모델이 그렇듯이 CNN 모델 역시 수학적인 모델이다. 필터가 어떻게 특징을 추출해내는지 알아보자 .\n",
    "MNIST 숫자 데이터는 흑백 이미지로 각 픽셀은 0부터 255 사이의 값 중 하나를 가지고 있다. 픽셀 안의 숫자0 은 흰색을 의미하며 255는 검은색 그리고 그 사이의 숫자는  \n",
    "흰색과 검은색 사이의 어떤 색(회색)을 의미한다.  \n",
    "만약 이미지 안에 흰색과 검은색만 존재한다면 아래 그림과 같이 0과 255로만 구성되어 있을 것이다. \n",
    "\n",
    "<img src=\"./images/CNN4.png\" align=\"left\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548cf403",
   "metadata": {},
   "source": [
    "위 그림에서 알수 있듯이 필터 안에는 특정한 숫자가 들어있고 필터와 이미지 영역의 겹치는 부분마다 곱셈이 이루어지고 필터에 4개의 픽셀이 있다면 4개의 영역이 곱해지고 \n",
    "곱해진 값은 최종적으로 더해진다.  \n",
    "최종값이 크다는 의미는 필터와 겹쳐진 부분이 많다는 의미이며 반대로 최종값이 작을 경우 필터와 겹치는 부분이 적었다라고 해석을 할 수 있다.  \n",
    "\n",
    "CNN 모델 안에는 각 특성의 개수만큼 필터가 필요하다.  \n",
    "보통 전반부 레이어에 존재하는 필터는 직선, 곡선 같은 기초적인 특성을 구별하기 위해 존재하고 후반부에 있는 필터는 동그라미,  \n",
    "세모 같은 조금더 고차원의 특징을 구별하기 위해 존재한다.   \n",
    "필터를 사용해서 모든 특징을 찾아낸후 , 이특징들은 다중 퍼셉트론의 입력값으로 들어가서 필터로 부터 구별된 특징을 기반으로 숫자 분류를 진행한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9570e15",
   "metadata": {},
   "source": [
    "<img src=\"./images/CNN5.png\" align=\"left\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd5bfa",
   "metadata": {},
   "source": [
    "스트라이드를 통해 얻어진 행렬을 피쳐 맵 (feature map)이라고 한다.   \n",
    "피처 맵을 활성화 함수에 넣어 구현한 행렬을 액티베이션 맵(activation map) 이라고 한다.  \n",
    "\n",
    "맥스 풀링(max pooling)은 지정된 영역에서 가장 큰 수치를 선택하고 나머지는 버린다.  \n",
    "아래 그림은 2*2 필터에 스트라이드를 적용한 피쳐 맵에 맥스 풀링을 적용한 예이다.  \n",
    "피쳐 맵의 크기가 줄어듬으로써 얻는 장점은 계산에 사용되는 파라미터의 개수가 줄어들어 계산 속도가 빨라지고 파라미터를 줄임으로써 모델의 분산을 줄이고 그에 따라   \n",
    "과대 적합의 가능성을 줄여준다.   \n",
    "<img src=\"./images/CNN6.png\" align=\"left\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb4adb",
   "metadata": {},
   "source": [
    "제로 패딩(zero padding)은 0으로 입력 행렬의 테두리를 감싸는 기술이다.  '\n",
    "스트라이드를 통해 입력된 행렬보다 작아진 행렬이 출력되고 작아진 만큼 정보 손실이 발생되므로 제로 패딩을 통해 입력 행렬의 크기를 크게 함으로써 스트라이드 이후에도 \n",
    "이미지 크기를 동일하게 유지할 수 있다.  \n",
    "\n",
    "<img src=\"./images/CNN7.png\" align=\"left\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c580ad",
   "metadata": {},
   "source": [
    "제로 패딩으로 인해 스트라이드할 공간이 더 많아졌다 만약 필터 크기가 3 * 3이고 스트라이드를 1픽셀씩 할 경우 피쳐 맵은 5 * 5 로 제로 패딩을 하기 전의 입력 행렬과 동일한 크기로 출력될 것이다. \n",
    "\n",
    "데이터 구조 변경하기 \n",
    "28 * 28 픽셀의 단색 이미지 이므로 데이터 형태를 28 * 28 * 1 로 맞춰준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c071b570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (50000, 28, 28, 1)\n",
      "x_val.shape: (10000, 28, 28, 1)\n",
      "x_test.shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN 모델에 입력하기 위해 데이터 셋을 생성한다. \n",
    "x_train = np.reshape(x_train, [50000,28,28,1])\n",
    "print('x_train.shape: {}'.format(x_train.shape)) \n",
    "x_val = np.reshape(x_val, [10000, 28, 28, 1])\n",
    "print('x_val.shape: {}'.format(x_val.shape)) \n",
    "x_test = np.reshape(x_test, [10000, 28, 28, 1])\n",
    "print('x_test.shape: {}'.format(x_test.shape)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec912c6a",
   "metadata": {},
   "source": [
    "데이터 정규화   \n",
    "데이터 정규화는 학습 시간을 단축하고 더 나은 성능을 발휘하도록 도와준다.   \n",
    "MINST 데이터의 모든 값은 0 부터 255 사이의 범위 안에 있으므로 255로 나눠줌으로써 모든 값을 0부터 1사이의 값으로 정규화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d930c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_val /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b498639c",
   "metadata": {},
   "source": [
    "실제값을 원-핫 인코딩으로 변경하기  \n",
    "손실 함수에서 크로스 엔트로피를 계산하기 위해 실제값을 원-핫 인코딩으로 변경한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1056bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes) # 학습 데이터 실제값 원-핫 인코딩\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes) # 학습 데이터 실제값 원 - 핫 인코딩\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) # 테스트 데이터 실제값 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f9273d",
   "metadata": {},
   "source": [
    "텐서프로우로 CNN 구현하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588613f",
   "metadata": {},
   "source": [
    "<img src=\"./images/CNN8.png\" align=\"left\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989cfd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 형태 그대로 28*28의 포멧을 입력 데이터로 사용하고 실제값은 0 부터 9 사이의 숫자이다.\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1]) # 학습 데이터\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 10]) # 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99fdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  random_normal()와 truncated_normal()는 매우 비슷하게 작동하지만 큰 차이가 있다.\n",
    "# 두메소드 모두 랜덤하게 값을 가져오는데 두방식의 가장 큰 차이는 truncated_normal() 메소드는 너무 작거나 너무 큰 값이 \n",
    "# 아닌 값으로 랜덤하게 가져온ㄴ다. \n",
    "# 딥러닝이나 머신러닝 중 너무 큰 기울기(기울기 폭주) 값이나 너무 작은 기울기(기울기 소멸) 값이 들어오면 작동을 멈춰버리는 현상이 발생되는데 \n",
    "# 이를 해결하기 위한 방법으로 truncated_normal() 메소드를 사용해서 난수를 발생시켜 사용한다.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "n = 100000\n",
    "A = tf.random.normal((n,))\n",
    "B= tf.truncated_normal((n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a7120ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    a = sess.run(A)\n",
    "    plt.hist(a, 1000, (-4.5, 4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fc72c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAASMElEQVR4nO3df4xlZ13H8ffH3VKIoAU61rq7OA2ukvLDhYy1piZiC1gKYUuCpKhQsclqLEkJKGz1DyGRBKJSJGrNYiuLotDwI93QopZSQviDwrQstT9AxlLsbpbuAKVAjDVbvv4xz9q7szM7d+bOnXvn3PcruZlznvOce79z7u7nPvPcc+9JVSFJ6pYfGXUBkqT1Z7hLUgcZ7pLUQYa7JHWQ4S5JHbR11AUAnHnmmTU9PT3qMiRpU7njjju+VVVTS20bi3Cfnp5mdnZ21GVI0qaS5BvLbXNaRpI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJf6NL33plGXIPXNcJekDuo73JNsSfKlJJ9o6+ckuT3JXJIPJ3lCaz+9rc+17dNDql2StIzVjNyvAu7rWX8XcE1V/QzwMHBFa78CeLi1X9P6SZI2UF/hnmQ78DLg79p6gAuBj7Qu+4FL2/Lutk7bflHrL0naIP2O3N8DvAX4YVt/OvDdqjrW1g8B29ryNuBBgLb9kdb/BEn2JJlNMjs/P7+26iVJS1ox3JO8HDhaVXes5wNX1b6qmqmqmampJb9rXpK0Rv1crOMC4BVJLgGeCPwY8JfAGUm2ttH5duBw638Y2AEcSrIV+HHg2+teuSRpWSuO3Kvq6qraXlXTwGXAp6vqN4HbgFe1bpcDN7blA22dtv3TVVXrWrW0Tjx3XV01yHnubwXelGSOhTn161r7dcDTW/ubgL2DlSiNni8C2mxWdQ3VqvoM8Jm2fD9w3hJ9/gf49XWoTZK0Rn5CVZI6yHDXxHPKRV1kuEtSBxnuktRBhrvE6qdmnMrRuDPcNTH6CeT16iONmuEuSR1kuEtLGGR07she48Bwl6QOMtylZUzvvclRuDYtw10TZz0D2/DXuDLcJamDDHdNlN6RtqNudZnhLi3iB5rUBYa7tE4MeY0Tw12dt1TorjWIDXBtFv1cIPuJSb6Q5MtJ7kny9tb+/iRfT3Kw3Xa19iR5b5K5JHclecGQfwdp5Ax9jZt+rsT0KHBhVf0gyWnA55J8sm37w6r6yKL+LwV2ttsvAte2n9KmZHBrM+rnAtlVVT9oq6e126kueL0b+EDb7/PAGUnOHrxUSVK/+ppzT7IlyUHgKHBLVd3eNr2jTb1ck+T01rYNeLBn90OtbfF97kkym2R2fn5+7b+BNIYc7WvU+gr3qnqsqnYB24HzkjwHuBp4FvALwNOAt67mgatqX1XNVNXM1NTU6qqWJJ3Sqs6WqarvArcBF1fVkTb18ijw98B5rdthYEfPbttbm9Qpjs41zvo5W2YqyRlt+UnAi4GvHJ9HTxLgUuDutssB4HXtrJnzgUeq6sgQapckLaOfs2XOBvYn2cLCi8ENVfWJJJ9OMgUEOAj8Xut/M3AJMAf8N/D6da9aknRKK4Z7Vd0FPH+J9guX6V/AlYOXJm0sp1nUJX5CVZ1hOEuPM9zVSQa9Jp3hLkkdZLhLUgcZ7uo0p2c0qQx3aR35YqJxYbhLQ3I86A18jYLhLkkdZLircxwxS4a7tKF8wdFGMdw1EQxVTRrDXZI6yHCXhmilvxj8i0LDYrhLG8Qg10Yy3CWpgwx3aYNN773JUbyGrp/L7D0xyReSfDnJPUne3trPSXJ7krkkH07yhNZ+elufa9unh/w7SP/P0JQW9DNyfxS4sKp+HtgFXNyujfou4Jqq+hngYeCK1v8K4OHWfk3rJw2NgS6dbMVwrwU/aKuntVsBFwIfae37WbhINsDutk7bflG7iLY0sXwB0kbra849yZYkB4GjwC3AfwLfrapjrcshYFtb3gY8CNC2PwI8fR1rliStoK9wr6rHqmoXsB04D3jWoA+cZE+S2SSz8/Pzg96dtGk5qtcwrOpsmar6LnAb8EvAGUm2tk3bgcNt+TCwA6Bt/3Hg20vc176qmqmqmampqbVVL0laUj9ny0wlOaMtPwl4MXAfCyH/qtbtcuDGtnygrdO2f7qqah1rliStYOvKXTgb2J9kCwsvBjdU1SeS3At8KMmfAl8Crmv9rwP+Ickc8B3gsiHULUk6hRXDvaruAp6/RPv9LMy/L27/H+DX16U6aYJM772JB975slGXoY7wE6qS1EGGuyR1kOGuTcnTB6VTM9wlqYMMd21qm/li2JuxZm0ehrskdZDhLkkdZLhr03E6Q1qZ4S6NAV+wtN4Md2mMGPJaL4a7NhXDT+qP4S6NMV/MtFaGuyR1kOEujSFH7BqU4S5JHWS4a9NydCstz3CXpA7q5xqqO5LcluTeJPckuaq1vy3J4SQH2+2Snn2uTjKX5KtJfm2Yv4Ak6WT9XEP1GPDmqrozyVOAO5Lc0rZdU1V/3ts5ybksXDf12cBPAZ9K8rNV9dh6Fi51ldNNWg8rjtyr6khV3dmWvw/cB2w7xS67gQ9V1aNV9XVgjiWutSpJGp5VzbknmWbhYtm3t6Y3JLkryfVJntratgEP9ux2iCVeDJLsSTKbZHZ+fn71lWuiOJqVVqfvcE/yZOCjwBur6nvAtcAzgV3AEeAvVvPAVbWvqmaqamZqamo1u0qSVtBXuCc5jYVg/2BVfQygqh6qqseq6ofA+3h86uUwsKNn9+2tTVqTzXy1JWlU+jlbJsB1wH1V9e6e9rN7ur0SuLstHwAuS3J6knOAncAX1q9kSdJK+jlb5gLgtcC/JznY2v4IeE2SXUABDwC/C1BV9yS5AbiXhTNtrvRMGUnaWCuGe1V9DsgSm24+xT7vAN4xQF2SpAH4CVVJ6iDDXWPFN01PNr33Jo+LVs1wl6QOMtw11iZ5xDrJv7sGZ7hLUgcZ7pLUQYa7JHWQ4a6x5ZyztHaGuyR1kOEuSR1kuGssOSVzMo+JVsNwlzYRA179MtwlqYMMd2mT6R29O5LXcgx3Seogw12SOqify+ztSHJbknuT3JPkqtb+tCS3JPla+/nU1p4k700yl+SuJC8Y9i8hTTqnZ7RYPyP3Y8Cbq+pc4HzgyiTnAnuBW6tqJ3BrWwd4KQvXTd0J7AGuXfeqJUmntGK4V9WRqrqzLX8fuA/YBuwG9rdu+4FL2/Ju4AO14PPAGYsupi1JGrJVzbknmQaeD9wOnFVVR9qmbwJnteVtwIM9ux1qbYvva0+S2SSz8/Pzq61bknQKfYd7kicDHwXeWFXf691WVQXUah64qvZV1UxVzUxNTa1mV0nSCvoK9ySnsRDsH6yqj7Xmh45Pt7SfR1v7YWBHz+7bW5vUF98clAbXz9kyAa4D7quqd/dsOgBc3pYvB27saX9dO2vmfOCRnukb6QQGuTQc/YzcLwBeC1yY5GC7XQK8E3hxkq8BL2rrADcD9wNzwPuA31//stUlBry0/rau1KGqPgdkmc0XLdG/gCsHrEsTYHGoG/LS+vETqpLUQYa7JHWQ4S5tUk5j6VQMd0nqIMNdY8FR6OCOH0OPpcBwl6ROMtwlqYMMd2mTcxpGSzHcJamDDHdJ6iDDXRvOaYTBeQy1EsNdkjrIcJc6xBG9jjPcJamDDHdJ6iDDXSPh9IE0XP1cZu/6JEeT3N3T9rYkhxddmen4tquTzCX5apJfG1bh2pwMdWlj9DNyfz9w8RLt11TVrna7GSDJucBlwLPbPn+TZMt6FStJ6s+K4V5VnwW+0+f97QY+VFWPVtXXWbiO6nkD1CdJWoNB5tzfkOSuNm3z1Na2DXiwp8+h1naSJHuSzCaZnZ+fH6AMSdJiaw33a4FnAruAI8BfrPYOqmpfVc1U1czU1NQay5AkLWVN4V5VD1XVY1X1Q+B9PD71chjY0dN1e2vTBPNNVGnjrSnck5zds/pK4PiZNAeAy5KcnuQcYCfwhcFKVBcY8NLG2rpShyT/DLwQODPJIeBPgBcm2QUU8ADwuwBVdU+SG4B7gWPAlVX12FAqlyQtq5+zZV5TVWdX1WlVtb2qrquq11bVc6vqeVX1iqo60tP/HVX1zKr6uar65HDL17hypD4+fC4mk59QlTrIQJfhLkkdZLhLUgcZ7lJHOTUz2Qx3rTtDRRo9w13qMF9oJ5fhrqEyXMaTz0v3Ge7ShDHYJ4PhLkkdZLhraBwhSqNjuGtdGejSeDDctWEM/tGZ3nuTx3/CGO6S1EGGuzRBHL1PDsNdkjrIcJfkiL6DVgz3JNcnOZrk7p62pyW5JcnX2s+ntvYkeW+SuSR3JXnBMIuXJC2tn5H7+4GLF7XtBW6tqp3ArW0d4KUsXDd1J7AHuHZ9ypQkrUY/l9n7LPCdRc27gf1teT9waU/7B2rB54EzFl1MWx3kn/TS+FnrnPtZPddN/SZwVlveBjzY0+9QaztJkj1JZpPMzs/Pr7EMjdrxYDfgpfEy8BuqVVVArWG/fVU1U1UzU1NTg5YhSeqx1nB/6Ph0S/t5tLUfBnb09Nve2jQBHL1L42Ot4X4AuLwtXw7c2NP+unbWzPnAIz3TN5KkDbJ1pQ5J/hl4IXBmkkPAnwDvBG5IcgXwDeDVrfvNwCXAHPDfwOuHULPGgKN0abytGO5V9ZplNl20RN8Crhy0KEnSYPyEqiR1kOEuSR1kuEs6ge+ndIPhrlXzP383LPU8+tx2h+EuSR204tky0nGO6rrH57S7HLlLUgcZ7jqJo7nJ5PPeLYa7VuR/+snjc775Ge6S1EGGuyR1kOGuJflnubS5Ge6S1EGGuyR1kOEuSR1kuEtalu+9bF4Dff1AkgeA7wOPAceqaibJ04APA9PAA8Crq+rhwcrUqPmffPL4nG9u6zFy/9Wq2lVVM219L3BrVe0Ebm3rkjap4yFv2G8uw5iW2Q3sb8v7gUuH8BjaIP6HljanQcO9gH9LckeSPa3trKo60pa/CZw14GNIklZp0K/8/eWqOpzkJ4Bbknyld2NVVZJaasf2YrAH4BnPeMaAZWgYHLVLm9dAI/eqOtx+HgU+DpwHPJTkbID28+gy++6rqpmqmpmamhqkDEnSImsO9yQ/muQpx5eBlwB3AweAy1u3y4EbBy1S0mj5V9zmM8i0zFnAx5Mcv59/qqp/SfJF4IYkVwDfAF49eJmSpNVYc7hX1f3Azy/R/m3gokGKkiQNxk+oSlIHGe6S1EGGuyR1kOEuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHWQ4S5JHWS4S1IHGe6S1EGGuyR1kOEuSR1kuEtSBw0t3JNcnOSrSeaS7B3W40iSTjaUcE+yBfhr4KXAucBrkpw7jMeSJJ1sWCP384C5qrq/qv4X+BCwe0iPJUlaZM0XyF7BNuDBnvVDwC/2dkiyB9jTVn+Q5KtDqqUfZwLfGuHjjxuPx4k8Hk3e5bFYZNTH46eX2zCscF9RVe0D9o3q8Xslma2qmVHXMS48HifyeDzOY3GicT4ew5qWOQzs6Fnf3tokSRtgWOH+RWBnknOSPAG4DDgwpMeSJC0ylGmZqjqW5A3AvwJbgOur6p5hPNY6GYvpoTHi8TiRx+NxHosTje3xSFWNugZJ0jrzE6qS1EGGuyR1kOG+SJI3J6kkZ466llFK8mdJvpLkriQfT3LGqGvaaH6FxuOS7EhyW5J7k9yT5KpR1zRqSbYk+VKST4y6lqUY7j2S7ABeAvzXqGsZA7cAz6mq5wH/AVw94no2lF+hcZJjwJur6lzgfODKCT8eAFcB9426iOUY7ie6BngLMPHvMlfVv1XVsbb6eRY+qzBJ/AqNHlV1pKrubMvfZyHUto22qtFJsh14GfB3o65lOYZ7k2Q3cLiqvjzqWsbQ7wCfHHURG2ypr9CY2DDrlWQaeD5w+4hLGaX3sDAQ/OGI61jWyL5+YBSSfAr4ySU2/THwRyxMyUyMUx2Pqrqx9fljFv4k/+BG1qbxlOTJwEeBN1bV90ZdzygkeTlwtKruSPLCEZezrIkK96p60VLtSZ4LnAN8OQksTEHcmeS8qvrmBpa4oZY7Hscl+W3g5cBFNXkfiPArNBZJchoLwf7BqvrYqOsZoQuAVyS5BHgi8GNJ/rGqfmvEdZ3ADzEtIckDwExVTey33yW5GHg38CtVNT/qejZakq0svJF8EQuh/kXgN8b8k9ZDk4VRz37gO1X1xhGXMzbayP0PqurlIy7lJM65azl/BTwFuCXJwSR/O+qCNlJ7M/n4V2jcB9wwqcHeXAC8Friw/Xs42EauGlOO3CWpgxy5S1IHGe6S1EGGuyR1kOEuSR1kuEtSBxnuktRBhrskddD/ATikND1mjYK2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    b = sess.run(B)\n",
    "    plt.hist(b, 1000, (-4.5, 4.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060db11",
   "metadata": {},
   "source": [
    "파라미터(가중치,바이어스)의 초기값을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8eb3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncated_normal()메소드는 0에서 거리가 아주 먼 값이 설정 되지 않게 도와준다.\n",
    "# 0에서 거리가 먼 값을 제외시키는 이유는 소프트 맥스 안의 시그모이드 함수의 특성 때문인데 시그모이드 함수 같은경우\n",
    "# 입력값이 매우 크거나 작으면 그 미분값이 0과 가까워져서 경사 하강법으로 파라미터를 변경하기 어려워진다. \n",
    "\n",
    "# 가중치를 만들어 리턴하는 함수 \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev= 0.1) # stddev 속성으로 난수가 발생되는 범위를 설정한다. \n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 바이어스를 만들어 리턴하는 함수\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ab1787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01309695]\n",
      " [-0.06420377]] [0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    w = weight_variable([2,1])\n",
    "    b = bias_variable([2])\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w),sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f93a4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터를 적용할 이미지 데이터와 필터를 넘겨받아 컨볼루션 레이어를 만들어 리턴하는 함수 \n",
    "# conv2d(필터를 적용할 이미지 데이터, 필터, strides, padding) 메소드는 이미지 데이터에 필터를 스트라이드 만큼 적용한다. \n",
    "# strides : 필터가 움직이는 간격으로 첫 번째 값과 4번째 값은 통상적으로 1을 사용하고 2번째 값은 가로 스트라이드 값, \n",
    "#           3번째 값은 세로 스트라이드 값을 입력한다.\n",
    "# padding : 입력 데이터 행렬 주위를 무의미한 값 (0)으로 감싸서 필터를 거쳐 나온 피쳐 맵의 크기가 작아지는 것을 방지하고 \n",
    "#           과대 적합이 발생하는 것을 방지할 수 있다.\n",
    "#           => SAME  : 텐서플로우가 자동으로 패딩을 적용해 입력값과 출력값의 크기를 같게한다. 패딩 적용 \n",
    "#           => VALID : 텐서플로우가 자동으로 패딩을 적용하지 않아 입력값 보다 출력값의 크기가 작아진다. 패딩 미적용\n",
    "def conv2d(x, W_conv): \n",
    "    return tf.nn.conv2d(x, W_conv, strides = [1,1,1,1], padding='SAME')\n",
    "    \n",
    "# 맥스 풀링을 실행해서 리턴하는 함수\n",
    "# max_pool(활성화 함수로 ReLu를 적용하고 맥스 플링을 적용할 데이터 , ksize, strides, padding) 메소드는 맥스 풀링을 적용한다.\n",
    "# ksize: 맥스 풀링의 크기로 [1, 2, 2, 1]는 2 * 2 크기로 묶어서 맥스 풀링을 한다는 의미이다.\n",
    "# strides, padding은 conv2d() 메소드와 의미가 같다 . \n",
    "# ksize, strides는 모두 필터의 크기를 의미하므로 동일한 값으로 지정해야 한다. \n",
    "def max_pool_2x2(h_conv):\n",
    "    return tf.nn.max_pool(h_conv, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e239934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번쨰 컨볼루션 레이어는 16개의  필터를 가지고 있고 필터의 크기는 5 * 5이고 바이어스는 필터(출력)의 개수만큼 만든다. \n",
    "W_conv1 = weight_variable([5,5,1,16]) # 1번째 컨볼루션 레이어의 필터 정의\n",
    "b_conv1 = bias_variable([16]) # 1번쨰 컨볼루션 레이어의 바이어스 \n",
    "\n",
    "# 활성화 함수로 ReLu를 사용한다.\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "\n",
    "# 1번쨰 컨블루션 레이어의 출력에 풀링레이어를 적용해서 액티베이션의 맵의 크기를 줄여준다 .\n",
    "# 액티베이션 맵의 크기를 줄여줌으로써 파라미터가 줄어들어 모델의 크기가 작아지고 과대 적합의 위험도 감소 시켜준다. \n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# 풀링 레이어에 의해 액티베이션 맵의 크기가 14 * 14가 되었고 이 값은 다음에 이어지는 2번째 컨볼루션 레이어의 입력으로 \n",
    "# 들어간다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c01bbf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 레이어는 32개의 필터를 가진다 . \n",
    "W_conv2 = weight_variable([5,5,16,32]) # 2번째 컨볼루션 레이어의 필터 정의\n",
    "b_conv2 = bias_variable([32]) # 2번쨰 컨볼루션 레이어의 바이어스 정의\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "# 풀링 레이어에 의해 액티베이션 맵의 크기는 7 *7 이된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d241b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC(Fully Connected Layers)\n",
    "# FC는 컨볼루션 레이어를 통해 추출된 이미지의 특징을 입력받아 0부터 9 사이의 숫자중 하나로 이미지를 분류한다. \n",
    "# FC2에 10개의 노드가 존재하는 이유는 FC2의 10개 노드의 값들을 소프트 맥스에 입력해서 각 노드별 확률을 구하기 위해서 이다.\n",
    "W_fc1 = weight_variable([7 *7 * 32 , 128])\n",
    "b_fc1 = bias_variable([128])\n",
    "\n",
    "# 2번째 컨볼루션 레이어의 맥스 풀링 결과를 행과 열을 변경해서 가중치와 행렬의 곱을 이용해 계산하고 활성화 함수로 \n",
    "# ReLu를 사용한다. \n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1 , 7*7 *32])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "W_fc2 = weight_variable([128, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6899a0",
   "metadata": {},
   "source": [
    "손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "028a2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의가 끝났으므로 모델을 합습시키기 위해서 손실 함수를 정의한다. 손실 함수로는 크로스 엔트로피를 사용한다 .\n",
    "# 실제값과 예측값의 크로스 엔트로피를 설정한다. \n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_conv, labels=y))\n",
    "# Adam 옵티마이저를 사용해 모델을 최적화 한다.\n",
    "train = tf.train.AdadeltaOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c094bc",
   "metadata": {},
   "source": [
    "정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6964807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict, 'float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e18454",
   "metadata": {},
   "source": [
    "학습 시킨다 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8a148dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:   0, 학습 정확도: 0.1660\n",
      "step:  10, 학습 정확도: 0.1600\n",
      "step:  20, 학습 정확도: 0.1980\n",
      "step:  30, 학습 정확도: 0.1560\n",
      "step:  40, 학습 정확도: 0.1940\n",
      "step:  50, 학습 정확도: 0.2100\n",
      "step:  60, 학습 정확도: 0.1920\n",
      "step:  70, 학습 정확도: 0.1700\n",
      "step:  80, 학습 정확도: 0.1840\n",
      "step:  90, 학습 정확도: 0.2080\n",
      "epoch: 0, 검증 정확도: 0.1985\n",
      "step:   0, 학습 정확도: 0.1820\n",
      "step:  10, 학습 정확도: 0.1780\n",
      "step:  20, 학습 정확도: 0.2320\n",
      "step:  30, 학습 정확도: 0.2060\n",
      "step:  40, 학습 정확도: 0.2260\n",
      "step:  50, 학습 정확도: 0.2640\n",
      "step:  60, 학습 정확도: 0.2500\n",
      "step:  70, 학습 정확도: 0.2320\n",
      "step:  80, 학습 정확도: 0.2460\n",
      "step:  90, 학습 정확도: 0.2580\n",
      "epoch: 1, 검증 정확도: 0.2873\n",
      "step:   0, 학습 정확도: 0.2940\n",
      "step:  10, 학습 정확도: 0.2860\n",
      "step:  20, 학습 정확도: 0.3360\n",
      "step:  30, 학습 정확도: 0.3160\n",
      "step:  40, 학습 정확도: 0.3420\n",
      "step:  50, 학습 정확도: 0.3520\n",
      "step:  60, 학습 정확도: 0.3420\n",
      "step:  70, 학습 정확도: 0.3480\n",
      "step:  80, 학습 정확도: 0.3620\n",
      "step:  90, 학습 정확도: 0.3540\n",
      "epoch: 2, 검증 정확도: 0.3870\n",
      "최종 모델 테스트 정확도: 0.3821\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "epoch_cnt =3 \n",
    "batch_size = 500\n",
    "iteration = len(x_train) // batch_size\n",
    "\n",
    "# 학습 시작 \n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            if i % 10 == 0 :\n",
    "                train_acc = accuracy.eval(feed_dict={x: x_train[start: end], y: y_train[start:end]})\n",
    "                print('step: {:3d}, 학습 정확도: {:6.4f}'.format(i,train_acc))\n",
    "            # === if\n",
    "            # Adam 옵티마이저를 사용한 최적화 함수를 실행한다.\n",
    "            train.run(feed_dict={x: x_train[start:end], y:y_train[start:end]})\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "        # ===== for i \n",
    "        \n",
    "        # 검증 데이터로 모델을 검증한다.\n",
    "        val_accuracy = accuracy.eval(feed_dict={x: x_val, y:y_val})\n",
    "        print('epoch: {}, 검증 정확도: {:6.4f}'.format(epoch, val_accuracy))\n",
    "        \n",
    "    # ==== for epoch\n",
    "    # 모델을 테스트 데이터로 테스트한 정확도를 계산해서 출력한다. \n",
    "    test_accuracy = accuracy.eval(feed_dict={x:x_test, y:y_test})\n",
    "    print('최종 모델 테스트 정확도: {:6.4f}'.format(test_accuracy))\n",
    "# ====== with"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
